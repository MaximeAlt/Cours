{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Sommaire<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#BOSTON-HOUSE\" data-toc-modified-id=\"BOSTON-HOUSE-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>BOSTON HOUSE</a></span><ul class=\"toc-item\"><li><span><a href=\"#Les-Regressions-Linéaire\" data-toc-modified-id=\"Les-Regressions-Linéaire-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Les Regressions Linéaire</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Dans-le-cadre-des-cours-de-Machine-Learning-(ECAM)-par-Manuel-Simoes\" data-toc-modified-id=\"Dans-le-cadre-des-cours-de-Machine-Learning-(ECAM)-par-Manuel-Simoes-1.1.0.1\"><span class=\"toc-item-num\">1.1.0.1&nbsp;&nbsp;</span>Dans le cadre des cours de Machine Learning (ECAM) par Manuel Simoes</a></span></li></ul></li><li><span><a href=\"#Utiliser-les-données-produitent-par-le-programme-précédent\" data-toc-modified-id=\"Utiliser-les-données-produitent-par-le-programme-précédent-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Utiliser les données produitent par le programme précédent</a></span></li><li><span><a href=\"#Un-exemple-de-graphe-que-vous-pouvez-créer-pour-comparer-les-données-prédites-aux-données-réelles\" data-toc-modified-id=\"Un-exemple-de-graphe-que-vous-pouvez-créer-pour-comparer-les-données-prédites-aux-données-réelles-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Un exemple de graphe que vous pouvez créer pour comparer les données prédites aux données réelles</a></span></li><li><span><a href=\"#Sur-quel-ensemble-définison-nous-la-normalisaton-à-appliquer-aux-données-?\" data-toc-modified-id=\"Sur-quel-ensemble-définison-nous-la-normalisaton-à-appliquer-aux-données-?-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Sur quel ensemble définison nous la normalisaton à appliquer aux données ?</a></span></li><li><span><a href=\"#À-quoi-sert-l'option-shuffle-(dans-la-création-de-2-jeux-de-données)-?\" data-toc-modified-id=\"À-quoi-sert-l'option-shuffle-(dans-la-création-de-2-jeux-de-données)-?-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>À quoi sert l'option shuffle (dans la création de 2 jeux de données) ?</a></span></li><li><span><a href=\"#Que-se-passe-t-il-quand-on-random-state-est-égale-à--1-(équivalent-à-None-dans-l'option-random_state)-?\" data-toc-modified-id=\"Que-se-passe-t-il-quand-on-random-state-est-égale-à--1-(équivalent-à-None-dans-l'option-random_state)-?-1.1.5\"><span class=\"toc-item-num\">1.1.5&nbsp;&nbsp;</span>Que se passe t-il quand on random state est égale à -1 (équivalent à None dans l'option random_state) ?</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOSTON HOUSE\n",
    "\n",
    "## Les Regressions Linéaire\n",
    "#### Dans le cadre des cours de Machine Learning (ECAM) par Manuel Simoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manu/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from itertools import combinations, product\n",
    "from ipywidgets import widgets, interact, interactive, fixed, interact_manual\n",
    "from ipywidgets import GridspecLayout, Button, Layout\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "\n",
    "# Ici vous pouvez charger vos données\n",
    "#####################################\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "Y = pd.DataFrame(boston.target)\n",
    "\n",
    "\n",
    "\n",
    "# Fonction principale d'apprentissage\n",
    "########################################\n",
    "def calculML(algo_spec, norm_spec, random_spec, shuffle_spec, splittest_spec, txt):\n",
    "\n",
    "    txt += \"# On importe les modules python\\n\"\n",
    "    txt += \"###############################\\n\"\n",
    "\n",
    "    txt += \"import pandas as pd\\n\"\n",
    "    txt += \"from sklearn.datasets import load_boston\\n\"\n",
    "    txt += \"from sklearn.model_selection import train_test_split\\n\"\n",
    "    txt += \"from sklearn.linear_model import LinearRegression, Ridge, ElasticNet, Lasso\\n\"\n",
    "    txt += \"import sklearn.preprocessing as preprocessing\\n\"\n",
    "    \n",
    "    txt += \"\\n# Chargement des donées\\n\"\n",
    "    txt += \"#########################\\n\"\n",
    "    txt += \"boston = load_boston()\\n\"\n",
    "    txt += \"df = pd.DataFrame(boston.data, columns=boston.feature_names)\\n\"\n",
    "    txt += \"Y = pd.DataFrame(boston.target)\\n\"\n",
    "    \n",
    "    randomNow = random_spec.value\n",
    "    \n",
    "    if randomNow == -1:\n",
    "        randomNow = None\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(df,\n",
    "                                                    Y, test_size=splittest_spec.value,\n",
    "                                                    shuffle=shuffle_spec.value,\n",
    "                                                    random_state=randomNow)\n",
    "    txt += \"\\n#Segmentation des données en 2 ensembles Train et Test\\n\"\n",
    "    txt += \"########################################################\\n\"\n",
    "    txt += \"X_train, X_test, Y_train, Y_test = train_test_split(df.drop(columns=['DIS', 'RAD']),\\n \\\n",
    "                                               Y, test_size=%s,\\n \\\n",
    "                                               shuffle=%s,\\n \\\n",
    "                                               random_state=%s) \\\n",
    "                                               \\n\" % (splittest_spec.value, shuffle_spec.value, randomNow)\n",
    "        \n",
    "    txt += \"\\n#Normalisation\\n\"\n",
    "    txt += \"################\\n\"\n",
    "        \n",
    "    normeNow = norm_spec.value\n",
    "    if normeNow != \"Aucune\":\n",
    "        if normeNow == \"MinMaxScaler\":\n",
    "            norme = preprocessing.MinMaxScaler()\n",
    "            txt += \"norme = preprocessing.MinMaxScaler()\\n\"\n",
    "        elif normeNow == \"StandardScaler\":\n",
    "            norme = preprocessing.StandardScaler()\n",
    "            txt += \"norme = preprocessing.StandardScaler()\\n\"\n",
    "        elif normeNow == \"RobustScaler\":\n",
    "            norme = preprocessing.StandardScaler()\n",
    "            txt += \"norme = preprocessing.RobustScaler()\\n\"\n",
    "            \n",
    "        fit_intercept = False\n",
    "        \n",
    "        ### Ici On normalise les données sur les tou\n",
    "        norme.fit(X_train)\n",
    "        X_train = norme.transform(X_train)\n",
    "        #### Ici\n",
    "        X_test = norme.fit_transform(X_test)\n",
    "        \n",
    "        txt += \"X_train = norme.fit_transform(X_train)\\n\"\n",
    "        X_test = norme.transform(X_test)\n",
    "        \n",
    "        txt += \"X_test = norme.transform(X_test)\\n\"\n",
    "        normalize = False\n",
    "    else:\n",
    "        fit_intercept = False\n",
    "        normalize = False\n",
    "\n",
    "    txt += \"\\n#Algorithme (avec l'entraînement)\\n\"\n",
    "    txt += \"###################################\\n\"\n",
    "\n",
    "    algoNow = algo_spec.value\n",
    "    if algoNow == \"LinearRegression\":\n",
    "        model = LinearRegression(fit_intercept=fit_intercept, normalize=normalize)\n",
    "        txt += \"model = LinearRegression(fit_intercept=%s, normalize=%s)\\n\" % (fit_intercept, normalize)\n",
    "        \n",
    "    elif algoNow == \"Ridge\":\n",
    "        model = Ridge(fit_intercept=fit_intercept, normalize=normalize)\n",
    "        txt += \"model = Ridge(fit_intercept=%s, normalize=%s)\\n\" % (fit_intercept, normalize)\n",
    "        \n",
    "    elif algoNow == \"ElasticNet\":\n",
    "        model = ElasticNet(fit_intercept=fit_intercept, normalize=normalize)\n",
    "        txt += \"model = ElasticNet(fit_intercept=%s, normalize=%s)\\n\" % (fit_intercept, normalize)\n",
    "        \n",
    "    elif algoNow == \"Lasso\":\n",
    "        model = Lasso(fit_intercept=fit_intercept, normalize=normalize)\n",
    "        txt += \"model = Lasso(fit_intercept=%s, normalize=%s)\\n\" % (fit_intercept, normalize)\n",
    "\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "    txt += \"model.fit(X_train, Y_train)\\n\"\n",
    "    \n",
    "    return [model, X_train, X_test, Y_train, Y_test, txt]\n",
    "\n",
    "\n",
    "def update(change):\n",
    "    global df2\n",
    "    global model, X_train, X_test, Y_train, Y_test, Y_pred\n",
    "    \n",
    "    txt = \"\"\n",
    "    model, X_train, X_test, Y_train, Y_test, txt  = calculML(walgo, wnorme,\n",
    "                                                             wRandom, wshuffle,\n",
    "                                                             wsplittest, txt)\n",
    "    txt += \"\\n# Test du modèle\\n\"\n",
    "    txt += \"##################\\n\"\n",
    "    Y_pred = model.predict(X_test)\n",
    "    txt += \"Y_pred = model.predict(X_test)\\n\"\n",
    "    txt += \"score = model.score(X_test, Y_test)\\n\"\n",
    "    txt += \"print(score)\\n\"\n",
    "    dftmp = pd.DataFrame({\"Train_size\":[X_train.shape[0]],\n",
    "                          \"Test_size\":[X_test.shape[0]],\n",
    "                          \"Algo\":[walgo.value], \"Random\":[wRandom.value],\n",
    "                          \"Normalisation\":[wnorme.value],\n",
    "                          \"Score\":[model.score(X_test, Y_test)],\n",
    "                          \"mean_absolute_error\":[mean_absolute_error(Y_test, Y_pred)],\n",
    "                          \"mean_squared_error\":[mean_squared_error(Y_test, Y_pred, squared=False)],\n",
    "                          \"r2_score\":[r2_score(Y_test, Y_pred)]\n",
    "                         })\n",
    "    df2 = df2.append(dftmp, ignore_index=True)\n",
    "    \n",
    "    wScore.clear_output()\n",
    "    with wScore:\n",
    "        display(df2)\n",
    "        \n",
    "    wPython.clear_output()\n",
    "    with wPython:\n",
    "        display(print(txt))\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "# Initialisation des widgets d'affichages\n",
    "ok_button = widgets.Button(description=\"Learn\")\n",
    "\n",
    "# text = widgets.Text(value='Travail sur Algorithme',\n",
    "#                     disabled=True, layout={'width': '100%', 'height': '100%'})\n",
    "\n",
    "output = widgets.Output(layout={'width': '100%',\n",
    "                                'height': '100%',\n",
    "                                'border': '1px solid black'})\n",
    "\n",
    "wsplittest = widgets.BoundedFloatText(value=0.25,\n",
    "                                        min=0.1,\n",
    "                                        max=1.0,\n",
    "                                        step=0.05,\n",
    "                                        description='split Test:',\n",
    "                                        disabled=False)\n",
    "\n",
    "walgo = widgets.Select(options=['LinearRegression', 'Ridge', 'ElasticNet', 'Lasso'],\n",
    "                        value='LinearRegression',\n",
    "                        description='Algorithme :',\n",
    "                        rows=4,\n",
    "                        disabled=False)\n",
    "\n",
    "wshuffle = widgets.Checkbox(value=False,\n",
    "                            description='shuffle',\n",
    "                            disabled=False)\n",
    "\n",
    "wnorme = widgets.Select(options=['MinMaxScaler', 'StandardScaler', 'RobustScaler', 'Aucune'],\n",
    "                        value='Aucune',\n",
    "                        description='Normalisation :',\n",
    "                        rows=4,\n",
    "                        disabled=False )\n",
    "\n",
    "wRandom = widgets.BoundedIntText(min=-1,\n",
    "                                value=42,\n",
    "                                description='random state :',\n",
    "                                disabled=False)\n",
    "\n",
    "wScore = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "wPython = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "layout = widgets.Layout(display='flex',\n",
    "                        flex_flow='row',\n",
    "                        border='solid',\n",
    "                        width='100%')\n",
    "\n",
    "df2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86176ac4803c45f59cbbc34e923310c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h4><b>1. Chargement des données</b></h4>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed921c7f6b84cadbd5867297d0efafa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='\\tNombre de feature : 506 \\n\\tNombre de ligne : 13'),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137004833a4a494091095f5501990a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h4><b>2. Nettoyer les données</b></h4>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e7cc80aab54344a82361e52bef01b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Dans notre cas les données sont OK'),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1480a5a12984511a0250ba06c9a68e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h4><b>3. Segmentation des données en 2 ensembles Train et Test</b></h4>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd21b5e521cd4049861559ea71d16738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(BoundedFloatText(value=0.25, description='split Test:', max=1.0, min=0.1, step=0.05), Checkbox(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415c9adec2684e188b5ff88e5effe765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h4><b>4. Normalisation des données</b></h4>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0491971166d24cbb918b52841b0d9bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Select(description='Normalisation :', index=3, options=('MinMaxScaler', 'StandardScaler', 'Robu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e3b1981eee34b27af65f5d7a928ee3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h4><b>5. Choix de l'algorithme</b></h4>\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20614aa80c3d405eb1f6edee33866e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Select(description='Algorithme :', options=('LinearRegression', 'Ridge', 'ElasticNet', 'Lasso')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf39cb51d0d4da4930d63c967110705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h4><b>6. Entraînement de l'algorithme</b></h4>\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a39b26b9c0742a8b4d61f5b51cef865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Learn', style=ButtonStyle()),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bdbef6dee8e460cadcbc97d39ba0b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h4><b>7. Mesure de la qualité des résultats</b></h4>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e241dab128c54e0e805c2544c13ad4ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(border='1px solid black')),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06eeb4b60ec54965b381805163306a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h4><b>6. Code Python associé.</b></h4>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096ed6718792401fb28c05af3e845edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(border='1px solid black')),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manu/anaconda3/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/manu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "/home/manu/anaconda3/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/manu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "/home/manu/anaconda3/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/manu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# Link\n",
    "# ok_button.on_click(functools.partial(update, df2=df2))\n",
    "# widgets.Box(children=[walgo, wnorme, wRandom], layout=layout)\n",
    "ok_button.on_click(update)\n",
    "line_box1 = widgets.HBox([wsplittest, wshuffle, wRandom])\n",
    "line_box2 = widgets.HBox([wnorme])\n",
    "line_box3 = widgets.HBox([walgo])\n",
    "line_box4 = widgets.HBox([ok_button])\n",
    "line_box5 = widgets.HBox([wScore])\n",
    "line_box6 = widgets.HBox([wPython])\n",
    "\n",
    "display(widgets.HTML(value=\"<h4><b>1. Chargement des données</b></h4>\"))\n",
    "display(\n",
    "    widgets.HBox([\n",
    "        widgets.Label(\n",
    "            value=\"\\tNombre de feature : %s \\n\\tNombre de ligne : %s\" %\n",
    "            (df.shape[0], df.shape[1]))\n",
    "    ]))\n",
    "\n",
    "display(widgets.HTML(value=\"<h4><b>2. Nettoyer les données</b></h4>\"))\n",
    "display(\n",
    "    widgets.HBox([widgets.Label(value=\"Dans notre cas les données sont OK\")]))\n",
    "\n",
    "display(\n",
    "    widgets.HTML(\n",
    "        value=\n",
    "        \"<h4><b>3. Segmentation des données en 2 ensembles Train et Test</b></h4>\"\n",
    "    ))\n",
    "display(line_box1)\n",
    "\n",
    "display(widgets.HTML(value=\"<h4><b>4. Normalisation des données</b></h4>\"))\n",
    "display(line_box2)\n",
    "\n",
    "display(widgets.HTML(value=\"<h4><b>5. Choix de l'algorithme</b></h4>\"))\n",
    "display(line_box3)\n",
    "display(widgets.HTML(value=\"<h4><b>6. Entraînement de l'algorithme</b></h4>\"))\n",
    "display(line_box4)\n",
    "\n",
    "display(\n",
    "    widgets.HTML(\n",
    "        value=\"<h4><b>7. Mesure de la qualité des résultats</b></h4>\"))\n",
    "display(line_box5)\n",
    "\n",
    "display(widgets.HTML(value=\"<h4><b>6. Code Python associé.</b></h4>\"))\n",
    "display(line_box6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utiliser les données produitent par le programme précédent\n",
    "- le tableau précédent est contenue dans le DataFrame df2\n",
    "- Les données originales (X) sont contenue dans le DataFrame df\n",
    "- Les données originales (Y) sont contenue dans le DataFrame Y\n",
    "- Vous pouvez utiliser les variables : X_train, Y_train, X_test, Y_test, Y_test, Y_pred\n",
    "- Le dernier modèle calculé est contenue dans la variable : model.\n",
    "\n",
    "Toutes ces variables, proviennent du dernier entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un exemple de graphe que vous pouvez créer pour comparer les données prédites aux données réelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# sns.set_style(\"whitegrid\")\n",
    "# sns.set_context(\"poster\")\n",
    "# plt.scatter(Y_test, Y_pred)\n",
    "# plt.xlabel(\"Prix: $Y_i$\")\n",
    "# plt.ylabel(\"Prix Prédit: $\\hat{Y}_i$\")\n",
    "# plt.title(\"Prix vs Prix Prédit: $Y_i$ vs $\\hat{Y}_i$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sur quel ensemble définison nous la normalisaton à appliquer aux données ?\n",
    "   X (X_train et X_test), X_train ou X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### À quoi sert l'option shuffle (dans la création de 2 jeux de données) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que se passe t-il quand on random state est égale à -1 (équivalent à None dans l'option random_state) ?\n",
    "Justifier la variation des résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Choisissez un autre jeux de données : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Sommaire",
   "title_sidebar": "Sommaire",
   "toc_cell": true,
   "toc_position": {
    "height": "232.217px",
    "left": "24px",
    "top": "225.133px",
    "width": "427.133px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
